dataset:
  train:  # LMDB
    type: MFQEv2Dataset
    
    # for lmdb
    root: /home/***/mfqe/
    gt_folder: train_raw_yuv/
    lq_folder: LDP/train_qp_down/QP32/
    ref_folder: LDP/train_qp_yuv/QP37/

    # for dataset
    gt_path: LDP_mfqev2_train_gt_QP32.lmdb
    lq_path: LDP_mfqev2_train_lq_QP32.lmdb
    ref_path: LDP_mfqev2_train_ref_QP32.lmdb

    meta_info_fp: meta_info.txt
    gt_size: 128  # ground truth patch size: gt_size * gt_size
    use_flip: True
    use_rot: True  # rotation per 90 degrees
    random_reverse: False

    # for datasampler
    enlarge_ratio: 300  # enlarge dataset by randomly cropping.
    # for dataloader
    num_worker_per_gpu: 12 # 12 in total. mainly affect IO speed
    batch_size_per_gpu: 4 # bs=32, divided by 4 GPUs

  val:  # Disk IO
    type: VideoTestMFQEv2Dataset
    root: /home/***/mfqe/
    gt_path: test_raw_yuv/
    lq_path: LDP/test_qp_down/QP32/
    ref_path: LDP/test_qp_yuv/QP37/
  test:
    type: VideoTestMFQEv2Dataset
    root: /home/***/mfqe/
    gt_path: test_raw_yuv/
    lq_path: LDP/test_qp_down/QP32/
    ref_path: LDP/test_qp_yuv/QP37/

network:
  radius: 3  # total num of input frame = 2 * radius + 1
  stdf:
    in_nc: 1  # 1 for Y
    out_nc: 48
    nf: 48  # num of feature maps
    nb: 3  # num of conv layers
    base_ks: 3
    deform_ks: 5  # size of the deformable kernel
  
  self_alig:
    in_nc: 1 # 1 for Y
    out_nc: 48
    nf: 48  # num of feature maps
    nb: 3  # num of conv layers
    deform_ks: 5
  
  extractor:
    in_nc: 1  # 1 for Y
    nf: 48 # num of feature maps
    base_ks: 3
  
  upnet:
    base_ks: 3
    nf: 48
    in_nc: 48
    scale_factor: 2

  attention:
    in_nc: 48  # 
    base_ks: 3
    nf: 48
    nb: 2

  fusion:
    in_nc: 48  # 
    out_nc: 1  # 1 for Y
    nf: 48
    base_ks: 3
    
    
train:
  exp_name: RCVSR_LDP_QP32  # default: timestr. None: ~
  random_seed: 7
  pre-val: False  # evaluate criterion before training, e.g., ori PSNR
  num_iter: !!float 10e+5
  interval_print: !!float 400
  interval_val: !!float 20e+3 # also save model
  pbar_len: 100
  phase: resume # resume,train

  optim:
    type: Adam
    lr: !!float 0.5e-4  # init lr of scheduler
    betas: [0.9, 0.999]
    eps: !!float 1e-08

  scheduler:
    is_on: False
    type: CosineAnnealingRestartLR
    periods: [!!float 5e+4, !!float 5e+4, !!float 5e+4, !!float 5e+4, !!float 5e+4, !!float 5e+4]  # epoch interval
    restart_weights: [1, 0.5, 0.5, 0.5, 0.5, 0.5]
    eta_min: !!float 1e-7

  loss:
    type: CharbonnierLoss
    eps: !!float 1e-5

  texloss:
    type: LogcoshLoss
    eps: !!float 1e-5

  criterion:
    type: PSNR
    unit: dB

test:
  restore_iter: 180000
  pbar_len: 100

  criterion:
    type: PSNR
    unit: dB